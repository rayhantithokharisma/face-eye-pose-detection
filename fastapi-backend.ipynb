{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b663df47-967b-4772-9629-8cf5fe5428be",
   "metadata": {},
   "source": [
    "# Deploy to FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0474051e-bd96-4f52-8e1a-810248260a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 18:24:59.494719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 18:24:59.507281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 18:24:59.511034: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 18:24:59.520390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 18:25:00.182142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725881101.325884   11994 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-09 18:25:01.348357: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from pydantic import BaseModel\n",
    "import base64\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "import tensorflow as tf\n",
    "from helpers import relative, relativeT\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh  # initialize the face mesh model\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "detector_model = tf.saved_model.load('./models/tf_retinaface_mbv2/')\n",
    "\n",
    "blue = (0, 0, 255)\n",
    "red = (255, 0, 0)\n",
    "green = (0,128,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70176b32-119d-40b0-9055-68681b726c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_face(frame, bbs, pointss):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : uint8\n",
    "        RGB image (numpy array).\n",
    "    bbs : float64, Size = (N, 4)\n",
    "        coordinates of bounding boxes for all detected faces.\n",
    "    pointss : flaot32, Size = (N, 10)\n",
    "        coordinates of landmarks for all detected faces.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bb : float64, Size = (5,)\n",
    "        coordinates of bounding box for the selected face.\n",
    "    points : float32\n",
    "        coordinates of five landmarks for the selected face.\n",
    "\n",
    "    \"\"\"\n",
    "    # select only process only one face (center ?)\n",
    "    offsets = [(bbs[:,0]+bbs[:,2])/2-frame.shape[1]/2,\n",
    "               (bbs[:,1]+bbs[:,3])/2-frame.shape[0]/2]\n",
    "    offset_dist = np.sum(np.abs(offsets),0)\n",
    "    index = np.argmin(offset_dist)\n",
    "    bb = bbs[index]\n",
    "    points = pointss[:,index]\n",
    "    return bb, points\n",
    "\n",
    "def are_coordinates_in_frame(frame, box, pts):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : uint8\n",
    "        RGB image (numpy array).\n",
    "    bbs : float64\n",
    "        coordinates of bounding box.\n",
    "    points : flaot32\n",
    "        coordinates of landmarks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    height = height +1.5*height\n",
    "    width = width +1.5*width\n",
    "    \n",
    "    if np.any(box <= 0) or np.any(box >= height) or np.any(box >= width):\n",
    "        return False\n",
    "    if np.any(pts <= 0) or np.any(pts >= height) or np.any(pts >= width):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def are_centered(frame, box, pts):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : uint8\n",
    "        RGB image (numpy array).\n",
    "    bbs : float64\n",
    "        coordinates of bounding box.\n",
    "    points : flaot32\n",
    "        coordinates of landmarks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = frame.shape[:2]\n",
    "    # height = height +1.5*height\n",
    "    # width = width +1.5*width\n",
    "    \n",
    "    if np.any(box <= 0) or np.any(box >= height) or np.any(box >= width):\n",
    "        return False\n",
    "    if np.any(pts <= 0) or np.any(pts >= height) or np.any(pts >= width):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "    \n",
    "            \n",
    "def draw_landmarks(frame, bb, points):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : uint8\n",
    "        RGB image\n",
    "    bb : float64, Size = (5,)\n",
    "        coordinates of bounding box for the selected face.\n",
    "    points : float32, Size = (10,)\n",
    "        coordinates of landmarks for the selected faces.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    bb = bb.astype(int)\n",
    "    points = points.astype(int)\n",
    "    # draw rectangle and landmarks on face\n",
    "    cv2.rectangle(frame, (bb[0], bb[1]), (bb[2], bb[3]), red, 1)\n",
    "    cv2.circle(frame, (points[0], points[5]), 2, blue, 2)# left eye\n",
    "    cv2.circle(frame, (points[1], points[6]), 2, blue, 2)# right eye\n",
    "    cv2.circle(frame, (points[2], points[7]), 2, blue, 2)# nose\n",
    "    cv2.circle(frame, (points[3], points[8]), 2, blue, 2)# mouth - left\n",
    "    cv2.circle(frame, (points[4], points[9]), 2, blue, 2)# mouth - right \n",
    "    \n",
    "    w = int(bb[2])-int(bb[0])# width\n",
    "    h = int(bb[3])-int(bb[1])# height\n",
    "    w2h_ratio = w/h# width to height ratio\n",
    "    eye2box_ratio = (points[0]-bb[0]) / (bb[2]-points[1])\n",
    "    font_size = 14\n",
    "    #cv2.putText(frame, \"Width (pixels): {}\".format(w), (10,30), font, font_size, red, 1)\n",
    "    #cv2.putText(frame, \"Height (pixels): {}\".format(h), (10,40), font, font_size, red, 1)\n",
    "    \n",
    "    # if eye2box_ratio > 1.5 or eye2box_ratio < 0.88:\n",
    "    #     cv2.putText(frame, \"Face: not in center of the bounding box\", (10, 140), font, font_size, blue, 1)\n",
    "    # if w2h_ratio < 0.7 or w2h_ratio > 0.9:\n",
    "    #     cv2.putText(frame, \"Face: long and narrow\", (10, 160), font, font_size, blue, 1)\n",
    "\n",
    "def find_smile(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : flaot32\n",
    "        coordinates of landmarks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    smile_ratio : float32\n",
    "        a value that determines if the face is smiling.\n",
    "    \"\"\"\n",
    "    dx_eyes = points[1] - points[0]# pixels between pupils\n",
    "    dx_mout = points[4] - points[3]# pixles between mouth corners\n",
    "    smile_ratio = dx_mout/dx_eyes    \n",
    "    return smile_ratio\n",
    "\n",
    "def find_roll(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : float32\n",
    "        coordinates of landmarks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flaot32\n",
    "        an indication of roll.\n",
    "\n",
    "    \"\"\"\n",
    "    return points[6] - points[5]\n",
    "\n",
    "def find_yaw(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : float32, Size = (10,)\n",
    "        coordinates of landmarks.\n",
    "    Returns\n",
    "    -------\n",
    "    float32\n",
    "        an indication of yaw.\n",
    "\n",
    "    \"\"\"\n",
    "    le2n = points[2] - points[0]\n",
    "    re2n = points[1] - points[2]\n",
    "    return le2n - re2n\n",
    "\n",
    "def find_pitch(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : float32, Size = (10,)\n",
    "        coordinates of landmarks.\n",
    "    Returns\n",
    "    -------\n",
    "    float32\n",
    "        an indication of pitch.\n",
    "    \"\"\"\n",
    "    eye_y = (points[5] + points[6]) / 2\n",
    "    mou_y = (points[8] + points[9]) / 2\n",
    "    e2n = eye_y - points[7]\n",
    "    n2m = points[7] - mou_y\n",
    "    return e2n / n2m\n",
    "\n",
    "def find_pose(points):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : float32, Size = (10,)\n",
    "        coordinates of landmarks for the selected faces.\n",
    "    Returns\n",
    "    -------\n",
    "    float32, float32, float32\n",
    "    \"\"\"\n",
    "    LMx = points[0:5]# horizontal coordinates of landmarks\n",
    "    LMy = points[5:10]# vertical coordinates of landmarks\n",
    "    \n",
    "    dPx_eyes = max((LMx[1] - LMx[0]), 1)\n",
    "    dPy_eyes = (LMy[1] - LMy[0])\n",
    "    angle = np.arctan(dPy_eyes / dPx_eyes) # angle for rotation based on slope\n",
    "    \n",
    "    alpha = np.cos(angle)\n",
    "    beta = np.sin(angle)\n",
    "    \n",
    "    # rotated landmarks\n",
    "    LMxr = (alpha * LMx + beta * LMy + (1 - alpha) * LMx[2] / 2 - beta * LMy[2] / 2) \n",
    "    LMyr = (-beta * LMx + alpha * LMy + beta * LMx[2] / 2 + (1 - alpha) * LMy[2] / 2)\n",
    "    \n",
    "    # average distance between eyes and mouth\n",
    "    dXtot = (LMxr[1] - LMxr[0] + LMxr[4] - LMxr[3]) / 2\n",
    "    dYtot = (LMyr[3] - LMyr[0] + LMyr[4] - LMyr[1]) / 2\n",
    "    \n",
    "    # average distance between nose and eyes\n",
    "    dXnose = (LMxr[1] - LMxr[2] + LMxr[4] - LMxr[2]) / 2\n",
    "    dYnose = (LMyr[3] - LMyr[2] + LMyr[4] - LMyr[2]) / 2\n",
    "    \n",
    "    # relative rotation 0 degree is frontal 90 degree is profile\n",
    "    Xfrontal = (-90+90 / 0.5 * dXnose / dXtot) if dXtot != 0 else 0\n",
    "    Yfrontal = (-90+90 / 0.5 * dYnose / dYtot) if dYtot != 0 else 0\n",
    "\n",
    "    return angle * 180 / np.pi, Xfrontal, Yfrontal\n",
    "\n",
    "def detect_faces(image, image_shape_max=640):\n",
    "    '''\n",
    "    Performs face detection using retinaface method with speed boost and \n",
    "    initial quality checks based on whole image size\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : uint8\n",
    "        image for face detection.\n",
    "    image_shape_max : int, optional\n",
    "        maximum size (in pixels) of image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float array\n",
    "        landmarks.\n",
    "    float array\n",
    "        bounding boxes.\n",
    "    flaot array\n",
    "        detection scores.\n",
    "    '''\n",
    "\n",
    "    image_shape = image.shape[:2]\n",
    "    \n",
    "    # perform image resize for faster detection    \n",
    "    if image_shape_max:\n",
    "        scale_factor = max([1, max(image_shape)/image_shape_max])\n",
    "    else:\n",
    "        scale_factor = 1\n",
    "        \n",
    "    if scale_factor > 1:        \n",
    "        scaled_image = cv2.resize(image, (0, 0), fx = 1 / scale_factor, \n",
    "                                  fy = 1 / scale_factor)\n",
    "        bbs_all, points_all = retinaface(scaled_image)\n",
    "        bbs_all[:,:4] *= scale_factor\n",
    "        points_all *= scale_factor\n",
    "    else:\n",
    "        bbs_all, points_all = retinaface(image)              \n",
    "    \n",
    "    scores = bbs_all[:,-1]\n",
    "    bbs = bbs_all[:, :4]\n",
    "    \n",
    "    return points_all, bbs, scores\n",
    "\n",
    "def retinaface(image):\n",
    "    \"\"\" retinaface face detector\"\"\"\n",
    "\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    \n",
    "    image_pad, pad_params = pad_input_image(image)    \n",
    "    image_pad = tf.convert_to_tensor(image_pad[np.newaxis, ...])\n",
    "    image_pad = tf.cast(image_pad, tf.float32)  \n",
    "   \n",
    "    outputs = detector_model(image_pad).numpy()\n",
    "\n",
    "    outputs = recover_pad_output(outputs, pad_params)\n",
    "    Nfaces = len(outputs)\n",
    "    \n",
    "    bbs = np.zeros((Nfaces,5))\n",
    "    lms = np.zeros((Nfaces,10))\n",
    "    \n",
    "    bbs[:,[0,2]] = outputs[:,[0,2]]*width\n",
    "    bbs[:,[1,3]] = outputs[:,[1,3]]*height\n",
    "    bbs[:,4] = outputs[:,-1]\n",
    "    \n",
    "    lms[:,0:5] = outputs[:,[4,6,8,10,12]]*width\n",
    "    lms[:,5:10] = outputs[:,[5,7,9,11,13]]*height\n",
    "    \n",
    "    return bbs, lms\n",
    "\n",
    "def pad_input_image(img, max_steps=32):\n",
    "    \"\"\"pad image to suitable shape - required for retinaface\"\"\"\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    img_pad_h = 0\n",
    "    if img_h % max_steps > 0:\n",
    "        img_pad_h = max_steps - img_h % max_steps\n",
    "\n",
    "    img_pad_w = 0\n",
    "    if img_w % max_steps > 0:\n",
    "        img_pad_w = max_steps - img_w % max_steps\n",
    "\n",
    "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
    "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
    "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
    "    pad_params = (img_h, img_w, img_pad_h, img_pad_w)\n",
    "\n",
    "    return img, pad_params\n",
    "\n",
    "def recover_pad_output(outputs, pad_params):\n",
    "    \"\"\"recover the padded output effect\"\"\"\n",
    "    img_h, img_w, img_pad_h, img_pad_w = pad_params\n",
    "    recover_xy = np.reshape(outputs[:, :14], [-1, 7, 2]) * \\\n",
    "        [(img_pad_w + img_w) / img_w, (img_pad_h + img_h) / img_h]\n",
    "    outputs[:, :14] = np.reshape(recover_xy, [-1, 14])\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b9190c-5b1e-435f-bca9-6ea1785e06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pose_gaze(img):\n",
    "    blue = (0, 0, 255)\n",
    "    red = (255, 0, 0)\n",
    "    green = (0,128,0)\n",
    "    image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image_rgb = cv2.flip(image_rgb, 1)\n",
    "\n",
    "    is_gazing = False\n",
    "    is_centered = False\n",
    "    \n",
    "    try:\n",
    "        landmarks, bboxes, scores = detect_faces(image_rgb, 720)\n",
    "    except:\n",
    "        print(\"Error: face detector error.\")\n",
    "        return {'is_gazing':is_gazing, 'is_no_face':False, 'is_error':True, 'is_centered':is_centered}\n",
    "\n",
    "    if len(bboxes) > 0:\n",
    "        lmarks = np.transpose(landmarks)\n",
    "        bbs = bboxes.copy()\n",
    "    \n",
    "        bb, lmarks_5 = one_face(image_rgb, bbs, lmarks)\n",
    "        if are_coordinates_in_frame(image_rgb, bb, lmarks_5):\n",
    "            is_centered = are_centered(image_rgb, bb, lmarks_5)\n",
    "            angle, Xfrontal, Yfrontal = find_pose(lmarks_5)\n",
    "            if Xfrontal > 50 or Xfrontal < -50:\n",
    "                is_gazing = True\n",
    "            if Yfrontal > 10 or Yfrontal < -35:\n",
    "                is_gazing = True\n",
    "            return {'is_gazing':is_gazing, 'is_no_face':False, 'is_error':False, 'is_centered':is_centered}\n",
    "            \n",
    "        else:\n",
    "            return {'is_gazing':is_gazing, 'is_no_face':False, 'is_error':False, 'is_centered':is_centered}\n",
    "            \n",
    "    else:\n",
    "        return {'is_gazing':is_gazing, 'is_no_face':True, 'is_error':False, 'is_centered':is_centered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9d283f-3d31-4ff4-a59a-468c6d8b5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_left_right_gaze(img):\n",
    "\n",
    "    blue = (0, 0, 255)\n",
    "    red = (255, 0, 0)\n",
    "    green = (0,128,0)\n",
    "    face_mesh = mp_face_mesh.FaceMesh(\n",
    "            max_num_faces=1,  # number of faces to track in each frame\n",
    "            refine_landmarks=True,  # includes iris landmarks in the face mesh model\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5)\n",
    "    img.flags.writeable = False\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # frame to RGB for the face-mesh model\n",
    "    results = face_mesh.process(img)\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  \n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    avg_brightness = gray.mean()\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        points = results.multi_face_landmarks[0]\n",
    "        right_pupil = relative(points.landmark[468], frame.shape)\n",
    "        left_pupil = relative(points.landmark[473], frame.shape)\n",
    "        # cv2.circle(frame, (left_pupil[0], left_pupil[1]), 2, blue, 2)\n",
    "        # cv2.circle(frame, (right_pupil[0], right_pupil[1]), 2, red, 2)\n",
    "        \n",
    "        \n",
    "        # corner eye\n",
    "        left_corner = relative(points.landmark[263], frame.shape)\n",
    "        right_corner = relative(points.landmark[33], frame.shape)\n",
    "        # cv2.circle(frame, (left_corner[0], left_corner[1]), 2, blue, 2)\n",
    "        # cv2.circle(frame, (right_corner[0], right_corner[1]), 2, red, 2)\n",
    "    \n",
    "        right_corner_inside = relative(points.landmark[133], frame.shape)\n",
    "        left_corner_inside = relative(points.landmark[362], frame.shape)\n",
    "        # cv2.circle(frame, (left_corner_inside[0], left_corner_inside[1]), 2, blue, 2)\n",
    "        # cv2.circle(frame, (right_corner_inside[0], right_corner_inside[1]), 2, red, 2)\n",
    "    \n",
    "    \n",
    "        right_upper = relative(points.landmark[159], frame.shape)\n",
    "        left_upper = relative(points.landmark[386], frame.shape)\n",
    "        # cv2.circle(frame, (left_upper[0], left_upper[1]), 2, blue, 2)\n",
    "        # cv2.circle(frame, (right_upper[0], right_upper[1]), 2, red, 2)\n",
    "    \n",
    "        left_pupil_ratio = (left_pupil[0] - left_corner_inside[0]) / (left_corner[0] - left_corner_inside[0])\n",
    "        right_pupil_ratio = (right_pupil[0] - right_corner[0]) / (right_corner_inside[0] - right_corner[0])\n",
    "    \n",
    "        left_gazing = left_pupil_ratio >=0.6 and right_pupil_ratio >= 0.6\n",
    "        right_gazing = left_pupil_ratio < 0.4 and right_pupil_ratio < 0.4\n",
    "    \n",
    "        is_gazing = left_gazing or right_gazing\n",
    "        return {'is_gazing':is_gazing, 'is_no_face':False, 'is_error':False, 'is_centered':True, 'left_pupil':left_pupil, 'right_pupil':right_pupil}\n",
    "    else:\n",
    "        return {'is_gazing':False, 'is_no_face':True, 'is_error':False, 'is_centered':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28c416c-9c64-4dfe-aae4-61c327ac0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "app = FastAPI()\n",
    "\n",
    "# class Frame(BaseModel):\n",
    "#     frame: str\n",
    "#     timestamp: str\n",
    "\n",
    "@app.post(\"/eye-tracking\")\n",
    "async def eye_tracking(request: Request):\n",
    "    # Decode base64 frame\n",
    "\n",
    "    image_bytes = await request.body()\n",
    "    nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    gazing_response = detect_left_right_gaze(img)\n",
    "\n",
    "    return gazing_response\n",
    "    \n",
    "@app.post(\"/pose-estimate\")\n",
    "async def pose_estimate(request: Request):\n",
    "    # Decode base64 frame\n",
    "\n",
    "    image_bytes = await request.body()\n",
    "    nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    gazing_response = detect_pose_gaze(img)\n",
    "\n",
    "    return gazing_response\n",
    "    # try:\n",
    "    #     image_bytes = await request.body()\n",
    "    #     nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "    #     img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    #     gazing_response = detect_left_right_gaze(img)\n",
    "\n",
    "    #     return gazing_response\n",
    "    # except:\n",
    "    #     return {'is_gazing':False, 'is_no_face':False, 'is_error':True}\n",
    "        \n",
    "def start_fastapi():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8080)\n",
    "\n",
    "\n",
    "    #cv2.putText(frame, f\"Avg Brightness : {avg_brightness}\", (10, 300), font, 0.4, green, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a25614-d54f-40c6-aa74-136325f53ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_fastapi()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vtenv-2",
   "language": "python",
   "name": "vtenv-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
